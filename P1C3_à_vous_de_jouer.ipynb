{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Étape 1 : Préparer l’environnement"
      ],
      "metadata": {
        "id": "XgF6EZrNe2rv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GxAByKzxd5t2"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, udf\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Créez une session Spark pour démarrer PySpark :"
      ],
      "metadata": {
        "id": "LQnO6VPfef8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Créez une session Spark\n",
        "spark = SparkSession.builder.appName(\"Manipulez des images avec PySpark\").getOrCreate()"
      ],
      "metadata": {
        "id": "PHTaFSdJeQAg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Étape 2 : Charger des images de chats et de chiens"
      ],
      "metadata": {
        "id": "J5M6Aaf3ezt-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le dataset Dogs vs Cats est disponible sur Kaggle : [Dogs vs Cats Dataset](https://www.kaggle.com/c/dogs-vs-cats/data).\n",
        "\n",
        "Téléchargez et extrayez les images dans un dossier (par exemple, cats_dogs/).\n",
        "\n",
        "**N'hésitez pas à réduire la taille du jeu de données** dans un premier temps. Quand on cuisine un code, on a pas besoin de tout le dataset ! Ce n'est qu'une fois que le code est bon qu'on test avec le dataset dans son ensemble. Dans mon cas, je n'ai conservé que 21 images par classe dans mon fichier cats_dogs_mini.zip.\n",
        "\n",
        "Puisque j'ai uploadé un fichier zippé, je dois d'abord le dézipper."
      ],
      "metadata": {
        "id": "xpFU0AAVejud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!unzip /content/chest_x_ray_mini.zip"
      ],
      "metadata": {
        "id": "LCBiTvkciWT0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Définissez le chemin vers votre dataset (à adapter selon votre structure de fichiers)\n",
        "DATASET_PATH = \"/content/chest_x_ray_mini\""
      ],
      "metadata": {
        "id": "rootgQcqq78M"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cette fonction charge une image, la redimensionne (pour correspondre à l’entrée du CNN), et la prétraite."
      ],
      "metadata": {
        "id": "tLxvhQYmqCIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chargez les chemins des fichiers et les classes (cat/dog)\n",
        "def extract_label(filepath):\n",
        "    return \"pneumonia\" if \"bacteria\" in filepath.split(\"/\")[-1] else \"normal\"\n",
        "\n",
        "def get_image_paths(directory):\n",
        "    image_paths = []\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "      for filename in files:\n",
        "        if filename.endswith(\".jpeg\"):\n",
        "            image_paths.append(os.path.join(root, filename))\n",
        "    return image_paths"
      ],
      "metadata": {
        "id": "vjWRoCkFqC5K"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calcul distribué :\n",
        "\n",
        "Cette partie du code est prit en charge automtiquement par PySpark pour être distribuée si possible. En effet, le DataFrame Spark est réparti entre les nœuds du cluster.\n",
        "\n",
        "Chaque nœud traite un sous-ensemble des données (par exemple, un lot d'images)."
      ],
      "metadata": {
        "id": "TVViylhG6cMB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chargez les images et leurs étiquettes (\"chat\" ou \"chien\") dans un DataFrame :"
      ],
      "metadata": {
        "id": "0AIEMrlJepxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Liste des chemins\n",
        "image_paths = get_image_paths(DATASET_PATH)\n",
        "\n",
        "# Créer un DataFrame Spark à partir des chemins\n",
        "image_df = spark.createDataFrame([(path, extract_label(path)) for path in image_paths], [\"path\", \"label\"])"
      ],
      "metadata": {
        "id": "_gohboM7enP_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Affichez quelques lignes du DataFrame\n",
        "image_df.show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McVzOLjYsOoG",
        "outputId": "b99b4672-50c1-4811-8764-721a352d303e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------------------+---------+\n",
            "|path                                                        |label    |\n",
            "+------------------------------------------------------------+---------+\n",
            "|/content/chest_x_ray_mini/pneumonia/person9_bacteria_38.jpeg|pneumonia|\n",
            "|/content/chest_x_ray_mini/pneumonia/person5_bacteria_15.jpeg|pneumonia|\n",
            "|/content/chest_x_ray_mini/pneumonia/person7_bacteria_24.jpeg|pneumonia|\n",
            "|/content/chest_x_ray_mini/pneumonia/person7_bacteria_29.jpeg|pneumonia|\n",
            "|/content/chest_x_ray_mini/pneumonia/person6_bacteria_22.jpeg|pneumonia|\n",
            "+------------------------------------------------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calcul distribué :\n",
        "Les opérations comme `groupBy` sont distribuées, chaque partition effectuant un traitement local avant agrégation globale."
      ],
      "metadata": {
        "id": "f0bEYt-z7GXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comptez le nombre d'images par classe\n",
        "image_df.groupBy(\"label\").count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whGQ54sfsY8n",
        "outputId": "6a0143e6-224f-4945-ab2b-99850b5bff4b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+\n",
            "|    label|count|\n",
            "+---------+-----+\n",
            "|pneumonia|   20|\n",
            "|   normal|   20|\n",
            "+---------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Étape 3 : Catégorisation automatique"
      ],
      "metadata": {
        "id": "m2twOtlb5yYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Charger le modèle pré-entrainé\n",
        "model = MobileNetV2(weights=\"imagenet\", include_top=False, pooling=\"avg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Y_sjn6TtW-g",
        "outputId": "48de39e4-4d14-44d8-f08c-7ae1b2fc118b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-0c01be329bf0>:2: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  model = MobileNetV2(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fonction pour extraire les caractéristiques d'une image\n",
        "def extract_features(path):\n",
        "    try:\n",
        "        img = load_img(path, target_size=(224, 224))\n",
        "        img_array = img_to_array(img)\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "        img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)\n",
        "        features = model.predict(img_array)\n",
        "        return features.flatten().tolist()\n",
        "    except Exception as e:\n",
        "        return None"
      ],
      "metadata": {
        "id": "H4zdArVAg06C"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calcul distribué :\n",
        "L'UDF `extract_features` est appliquée en parallèle sur chaque partition des données."
      ],
      "metadata": {
        "id": "K4AEK_Ze7RTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Déclarez la fonction utilisateur (UDF)\n",
        "from pyspark.sql.types import ArrayType, FloatType\n",
        "feature_udf = udf(extract_features, ArrayType(FloatType()))"
      ],
      "metadata": {
        "id": "7I2x0gGrtaZw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajoutez une colonne avec les caractéristiques extraites\n",
        "image_df = image_df.withColumn(\"features\", feature_udf(col(\"path\")))"
      ],
      "metadata": {
        "id": "ntl2ai8Rtrdi"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Affichez le DataFrame avec les nouvelles colonnes\n",
        "image_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0X8gJqXttyy",
        "outputId": "4a97cc0a-02bd-4947-ad9d-7d60c9b6de72"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+--------------------+\n",
            "|                path|    label|            features|\n",
            "+--------------------+---------+--------------------+\n",
            "|/content/chest_x_...|pneumonia|[0.49183893, 0.0,...|\n",
            "|/content/chest_x_...|pneumonia|[0.058421895, 0.0...|\n",
            "|/content/chest_x_...|pneumonia|[0.7625137, 0.0, ...|\n",
            "|/content/chest_x_...|pneumonia|[0.38426328, 0.0,...|\n",
            "|/content/chest_x_...|pneumonia|[0.63174874, 0.05...|\n",
            "+--------------------+---------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Réalisez une classification simple avec les caractéristiques extraites.\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.linalg import Vectors, VectorUDT\n",
        "from pyspark.sql.functions import udf"
      ],
      "metadata": {
        "id": "x1iROSAxtwMZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir les caractéristiques en format de vecteurs compatibles avec Spark ML\n",
        "def convert_array_to_vector(features):\n",
        "    return Vectors.dense(features)"
      ],
      "metadata": {
        "id": "k1DmJ4rmvC_b"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir les caractéristiques et les labels en un format utilisable par Spark ML\n",
        "array_to_vector_udf = udf(lambda features: Vectors.dense(features) if features else None, VectorUDT())\n",
        "vectorized_df = image_df.withColumn(\"features_vec\", array_to_vector_udf(col(\"features\")))"
      ],
      "metadata": {
        "id": "6Thbhcy4tzWx"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Indexer les labels pour la classification\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "label_indexer = StringIndexer(inputCol=\"label\", outputCol=\"label_index\")\n",
        "data = label_indexer.fit(vectorized_df).transform(vectorized_df)"
      ],
      "metadata": {
        "id": "aHPulPCsus3k"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Diviser les données en ensembles d'entraînement et de test\n",
        "train, test = data.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "_g_-x5LzvZ50"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calcul distribué :\n",
        "Spark ML divise les données d'entraînement entre les nœuds pour entraîner le modèle de manière parallèle."
      ],
      "metadata": {
        "id": "x8_hsrVt7hFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Entraîner un modèle de régression logistique\n",
        "lr = LogisticRegression(featuresCol=\"features_vec\", labelCol=\"label_index\")\n",
        "model = lr.fit(train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-zze11dvcNU",
        "outputId": "4f867502-aa5c-4700-e127-7e2edcfef7b7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 294 ms, sys: 35.1 ms, total: 329 ms\n",
            "Wall time: 52.4 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Évaluer le modèle sur les données de test\n",
        "predictions = model.transform(test)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label_index\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Précision du modèle : {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnznyKkdvdz1",
        "outputId": "448deff8-2ca2-46a2-a68d-e0f456528f72"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Précision du modèle : 0.8\n",
            "CPU times: user 106 ms, sys: 11.9 ms, total: 117 ms\n",
            "Wall time: 17.3 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "woGwjMVVvf9M"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}